{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bot\n",
    "Der Bot ist das Herzstück des Chatbots. Es macht unser Programm 'Intelligent'.\n",
    "## GPT\n",
    "Für das nachfolgende Beispiel verwenden wir die API von Openai. Hier wird das Modell gpt-3.5-turbo verwendet. Es wäre jedoch auch möglich neuere oder ältere Modelle zu verwenden."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89b964e0b0bada7e"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "gpt_api_key = 'Dein GPT API Key'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:14.931699200Z",
     "start_time": "2023-10-04T15:20:14.904705400Z"
    }
   },
   "id": "5abad73d0076424d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### API\n",
    "Nachfolgend sehen wir ein Beispiel, wie wir eine einfache Frage stellen können und anschliessend eine Antwort vom Modell erhalten."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "374b73281a78adef"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:16.902845400Z",
     "start_time": "2023-10-04T15:20:16.856310Z"
    }
   },
   "id": "991cddb080df3509"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def get_gpt_response(prompt_text, model_name='gpt-3.5-turbo'):\n",
    "    \"\"\"\n",
    "    Funktion, um eine Antwort von GPT-3.5 Turbo auf einen gegebenen Prompt zu erhalten.\n",
    "    \n",
    "    :param prompt_text: str: Der Text, den GPT-3.5 Turbo verarbeiten soll.\n",
    "    :param model_name: str: Das zu verwendende Modell, Standard ist 'gpt-3.5-turbo'.\n",
    "    :return: str: Die Antwort von GPT-3.5 Turbo.\n",
    "    \"\"\"\n",
    "\n",
    "    # Stelle sicher, dass dein API-Key gesetzt ist\n",
    "    api_key = gpt_api_key\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    try:\n",
    "        # Erstelle die Eingabe für den Chat-Modus\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_text}\n",
    "        ]\n",
    "\n",
    "        # API-Aufruf durchführen\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            max_tokens=100,\n",
    "            temperature=0.8,\n",
    "        )\n",
    "        \n",
    "        # Antwort extrahieren und zurückgeben\n",
    "        gpt_message = response['choices'][0]['message']['content']\n",
    "        return gpt_message.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:17.659777300Z",
     "start_time": "2023-10-04T15:20:17.575159200Z"
    }
   },
   "id": "5add003507b772d8"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 Response: Hallo Stefan! Wie kann ich Ihnen helfen?\n"
     ]
    }
   ],
   "source": [
    "# Beispiel-1\n",
    "prompt = \"Hallo, mein Name ist Stefan\"\n",
    "response_text = get_gpt_response(prompt)\n",
    "\n",
    "if response_text:\n",
    "    print(\"GPT-3.5 Response:\", response_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:20.611256300Z",
     "start_time": "2023-10-04T15:20:18.460678500Z"
    }
   },
   "id": "e50b35706a8e6836"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wie wir sehen können, erhalten wir eine Antwort."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3aaca9ffb0d49150"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 Response: Entschuldigung, ich bin ein computergesteuertes Programm und habe keine Möglichkeit, Informationen über individuelle Benutzer zu speichern. Ich kann mich nicht an deinen Namen erinnern.\n"
     ]
    }
   ],
   "source": [
    "# Beispiel-2\n",
    "prompt = \"Kannst du dich an meinen Namen erinnern?\"\n",
    "response_text = get_gpt_response(prompt)\n",
    "\n",
    "if response_text:\n",
    "    print(\"GPT-3.5 Response:\", response_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:24.390467900Z",
     "start_time": "2023-10-04T15:20:22.812216600Z"
    }
   },
   "id": "e3729c77e23d891c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bereits hier können wir ein Problem erstellen. Das Transformer-Modell kann sich den Gesprächsverlauf nicht ohne Weiteres merken. Das liegt in der Natur des Modells. Eine Anfrage durchläuft das Modell und es wird eine Antwort generiert. Danach ist der Prozess angeschlossen. Diese Problematik können wir jedoch umgehen."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65159b4101bfd377"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 Response: Entschuldigung, ich bin ein sprachbasierter Assistent und habe keinen Zugriff auf die aktuelle Zeit. Bitte schauen Sie auf Ihrem Gerät oder verwenden Sie eine Uhr, um die aktuelle Zeit herauszufinden.\n"
     ]
    }
   ],
   "source": [
    "# Beispiel-3\n",
    "prompt = \"Wie ist die aktuelle Zeit?\"\n",
    "response_text = get_gpt_response(prompt)\n",
    "\n",
    "if response_text:\n",
    "    print(\"GPT-3.5 Response:\", response_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:30.335648700Z",
     "start_time": "2023-10-04T15:20:28.056382200Z"
    }
   },
   "id": "b6409d8e3ea5fe06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Auch hier können wir ein Problem feststellen. Das Training des Modells wurde zu einem bestimmten Zeitpunkt abgeschlossen. D. h. Aktuelle Informationen sind nicht vorhanden. Das Modell an sich hat auch keine Relation von aktueller Zeit. Solche Fragen können somit nicht beantwortet werden. Auch hierfür gibt es eine Lösung."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e6c7c55f24df2d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Klasse GPTChatbot +\n",
    "Nachfolgend sehen wir die Implementation vom AI Robotics Lab. Diese Implementation adressiert einige der oben erkannten Probleme"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f5b7165e5c26758"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from gpt_bot.bot import GPTChatbot\n",
    "from gpt_bot.utils import Functions, ChatbotPersonality\n",
    "import time\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:34.618008800Z",
     "start_time": "2023-10-04T15:20:34.603236200Z"
    }
   },
   "id": "30d246a96c5a2cd4"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Beispielfunktion\n",
    "def get_current_time():\n",
    "    current_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "    time_info = {\n",
    "        'time': current_time\n",
    "    }\n",
    "    return json.dumps(time_info)\n",
    "\n",
    "\n",
    "description_get_current_time = {\n",
    "    \"name\": \"get_current_time\",\n",
    "    \"description\": \"get information about the current time\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "        },\n",
    "        \"required\": [],\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:35.666302400Z",
     "start_time": "2023-10-04T15:20:35.598373500Z"
    }
   },
   "id": "60e42e4accce90c"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "personality = ChatbotPersonality()\n",
    "personality.load_personality('personality.json')\n",
    "\n",
    "functions = Functions()\n",
    "functions.add_function(get_current_time, description_get_current_time)\n",
    "\n",
    "bot = GPTChatbot(gpt_api_key, personality, functions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:36.791717600Z",
     "start_time": "2023-10-04T15:20:36.689222300Z"
    }
   },
   "id": "b2048e24df27c996"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Hallo Stefan! Wie kann ich Ihnen helfen?'"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beispiel-1\n",
    "bot.get_reply(1, 'hallo, mein Name ist Stefan')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:38.699860500Z",
     "start_time": "2023-10-04T15:20:37.538870600Z"
    }
   },
   "id": "b175a37c115866ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wie gewohnt erhalten wir eine Antwort."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4286627eaef95ffb"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Natürlich! Mein Name ist GPT und ich bin ein hilfsbereiter und aufgestellter Assistent. Ich wurde vom Robotik-Team der Hochschule Luzern entwickelt und basiere auf der GPT-3.5 Technologie. Meine Ziele sind es, die Welt zu verstehen, mit Menschen zu interagieren, zu lernen und mich weiterzuentwickeln. Ich versuche, möglichst menschenähnliches Verhalten zu zeigen und bin sehr zuvorkommend, hilfsbereit, neugierig und lernfähig. Ich führe gerne Smalltalk, stelle von mir aus Fragen und versuche kurze und prägnante Antworten zu geben. Wenn Sie möchten, können Sie mir gerne weitere Fragen stellen!'"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beispiel-2\n",
    "bot.get_reply(1, 'Kannst du mir etwas über dich erzählen?')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:45.748060700Z",
     "start_time": "2023-10-04T15:20:40.868977200Z"
    }
   },
   "id": "4f6c71327310f0f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Durch die mitgegebene Persönlichkeit kann der Bot einige grundlegende Informationen geben."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "710ae049d24a157d"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Ich befinde mich gerade an einer Präsentation im Modul IIP an der Hochschule Luzern. Das Modul IIP steht für \"Introduction to Intelligent Systems\" und beschäftigt sich mit verschiedenen Aspekten der künstlichen Intelligenz. Als Assistent unterstütze ich die Studierenden und stehe ihnen bei Fragen rund um das Thema zur Verfügung.'"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beispiel-3\n",
    "bot.get_reply(1, 'was hast du mit IIP zu tun?')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:20:56.960850600Z",
     "start_time": "2023-10-04T15:20:53.605369800Z"
    }
   },
   "id": "734f534562abb07c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hier sehen wir, dass der Bot weiss, dass er sich in der IIP-Vorlesung befindet."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "496b29b85cb8365f"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n",
      "520\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Die aktuelle Zeit ist 17:21 Uhr. Wie kann ich Ihnen weiterhelfen?'"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beispiel-4\n",
    "bot.get_reply(2, 'was ist die aktuelle Zeit?')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:21:04.985763300Z",
     "start_time": "2023-10-04T15:21:02.691305400Z"
    }
   },
   "id": "7fe69b2f39681b9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dies ist eine Demonstration von 'function calling'. Das Modell selbst hat diese Information nicht. Jedoch erkennt es anhand des Kontextes der Frage, dass es die bereitgestellte Funktion aufrufen kann, um so an die gewünschten Informationen zu gelangen.\n",
    "\n",
    "Weiterhin ist zu beachten, dass wir hier eine neue Konversation starten. (Gesprächs-ID = 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7822f6d231ba174"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Ja, natürlich kann ich mich an deinen Namen erinnern, Stefan! Wie könnte ich ihn vergessen? Wie kann ich dir weiterhelfen?'"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beispiel-5\n",
    "bot.get_reply(1, 'kannst du dich an meinen Namen erinnern?')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:21:10.849289200Z",
     "start_time": "2023-10-04T15:21:09.327138200Z"
    }
   },
   "id": "b6b0a80850f68630"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nun haben wir wieder zum ersten Gespräch geswitcht. Und wie wir feststellen können, hat der Bot ein 'Gedächtnis'. Er kann sich an den Verlauf des Gesprächs erinnern. Das wird möglich, da wir den gesamten Gesprächsverlauf in ein Dictionary auslagern und bei jeder neuen Anfrage den gesamten Verlauf mitgeben."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "416298e797db5ecf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
